{"cells":[{"cell_type":"code","source":["#INPUT: train.csv\n#Output: \n\"\"\"\n\n1. Clean up wrong X and Y values (very few of them)\n\n2. visualize data.\n\n2. Parse input to get features: for e.g: get date, time, year, month, etc..)\n\n3. Select, and generate features.\n\n3. Remove outliers.\n\n4. do PCA\n\nOutput: train dataframe with features and labels column\n\n        test dataframe with features and lables column\n\n        visuals to provide insights on data that help select, and tune the models.       \n\n a toolbox list to choose from:\n\n         Typical graphical techniques used in EDA are\n\n\nBox plot\n\nHistogram\n\nMulti-vari chart\n\nRun chart\n\nPareto chart\n\nScatter plot\n\nStem-and-leaf plot\n\nParallel coordinates\n\nOdds ratio\n\nTargeted projection pursuit\n\nGlyph-based visualization methods such as PhenoPlot[8] and Chernoff faces\n\nProjection methods such as grand tour, guided tour and manual tour\n\nInteractive versions of these plots\n\n        Dimensionality reduction:\n\nMultidimensional scaling\n\nPrincipal component analysis (PCA)\n\nMultilinear PCA\n\nNonlinear dimensionality reduction (NLDR)\n\n        Typical quantitative techniques are:\nMedian polish\n\nTrimean\n\nOrdination\n\nHistory\n\n        \n\"\"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[1]: &#39;\\n\\n1. Clean up wrong X and Y values (very few of them)\\n\\n2. visualize data.\\n\\n2. Parse input to get features: for e.g: get date, time, year, month, etc..)\\n\\n3. Select, and generate features.\\n\\n3. Remove outliers.\\n\\n4. do PCA\\n\\nOutput: train dataframe with features and labels column\\n\\n        test dataframe with features and lables column\\n\\n        visuals to provide insights on data that help select, and tune the models.       \\n\\n a toolbox list to choose from:\\n\\n         Typical graphical techniques used in EDA are\\n\\n\\nBox plot\\n\\nHistogram\\n\\nMulti-vari chart\\n\\nRun chart\\n\\nPareto chart\\n\\nScatter plot\\n\\nStem-and-leaf plot\\n\\nParallel coordinates\\n\\nOdds ratio\\n\\nTargeted projection pursuit\\n\\nGlyph-based visualization methods such as PhenoPlot[8] and Chernoff faces\\n\\nProjection methods such as grand tour, guided tour and manual tour\\n\\nInteractive versions of these plots\\n\\n        Dimensionality reduction:\\n\\nMultidimensional scaling\\n\\nPrincipal component analysis (PCA)\\n\\nMultilinear PCA\\n\\nNonlinear dimensionality reduction (NLDR)\\n\\n        Typical quantitative techniques are:\\nMedian polish\\n\\nTrimean\\n\\nOrdination\\n\\nHistory\\n\\n        \\n&#39;</div>"]}}],"execution_count":1},{"cell_type":"code","source":["filename=\"/FileStore/tables/train.csv\"\ndata=spark.read.csv(filename, header=True, inferSchema=True)\nprint(data.count())\nprint(len(data.columns))\ndata.printSchema() #the data was inferred properly. Class is an int. Features are double."],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">878049\n9\nroot\n-- Dates: timestamp (nullable = true)\n-- Category: string (nullable = true)\n-- Descript: string (nullable = true)\n-- DayOfWeek: string (nullable = true)\n-- PdDistrict: string (nullable = true)\n-- Resolution: string (nullable = true)\n-- Address: string (nullable = true)\n-- X: double (nullable = true)\n-- Y: double (nullable = true)\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["\"\"\"\nDates - timestamp of the crime incident\nCategory - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\nDescript - detailed description of the crime incident (only in train.csv)\nDayOfWeek - the day of the week\nPdDistrict - name of the Police Department District\nResolution - how the crime incident was resolved (only in train.csv)\nAddress - the approximate street address of the crime incident \nX - Longitude\nY - Latitude\n\"\"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: &#39;\\nDates - timestamp of the crime incident\\nCategory - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\\nDescript - detailed description of the crime incident (only in train.csv)\\nDayOfWeek - the day of the week\\nPdDistrict - name of the Police Department District\\nResolution - how the crime incident was resolved (only in train.csv)\\nAddress - the approximate street address of the crime incident \\nX - Longitude\\nY - Latitude\\n&#39;</div>"]}}],"execution_count":3},{"cell_type":"code","source":["#Parsing the time column to generate features, year, month, day, hour, season\nfrom pyspark.sql.functions import col, hour, minute, second, year, month, dayofmonth, date_format\n\ndef season(month):\n  switcher={\n    1:'winter',\n    2:'winter',\n    3:'spring',\n    4:'spring',\n    5:'spring',\n    6:'summer',\n    7:'summer',\n    8:'summer',\n    9:'autumn',\n    10:'autumn',\n    11:'autumn',\n    12:'winter'\n  }\n  return switcher.get(month,\"NA\")\n\nfrom pyspark.sql.types import StringType\nseason_udf_string= udf(lambda x: season(x), StringType())\n\ndata = data.withColumn(\"hour\", hour(col(\"Dates\"))).withColumn(\"minute\", minute(col(\"Dates\"))).withColumn(\"second\", second(col(\"Dates\"))).withColumn(\"dayOfMonth\", dayofmonth(col(\"Dates\"))).withColumn(\"year\", year(col(\"Dates\"))).withColumn(\"month\", month(col(\"Dates\"))).withColumn(\"weekday\", date_format(col(\"Dates\"), \"EEEE\")).withColumn(\"season\", season_udf_string(col(\"month\"))).drop(col(\"Dates\"))\n\ndata.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Category: string (nullable = true)\n-- Descript: string (nullable = true)\n-- DayOfWeek: string (nullable = true)\n-- PdDistrict: string (nullable = true)\n-- Resolution: string (nullable = true)\n-- Address: string (nullable = true)\n-- X: double (nullable = true)\n-- Y: double (nullable = true)\n-- hour: integer (nullable = true)\n-- minute: integer (nullable = true)\n-- second: integer (nullable = true)\n-- dayOfMonth: integer (nullable = true)\n-- year: integer (nullable = true)\n-- month: integer (nullable = true)\n-- weekday: string (nullable = true)\n-- season: string (nullable = true)\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["#1. Data Wrangling to audit the quality of the data and perform all the necessary actions to clean the dataset.\n#1- check how many categorical and numerical features we have\ncat_cols = [item[0] for item in data.dtypes if item[1].startswith('string')] \nprint(str(len(cat_cols)) + '  categorical features')\n\nnum_var = [i[0] for i in data.dtypes if ((i[1]=='int') | (i[1]=='double')) ]\nprint(str(len(num_var)) + '  numerical features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">8  categorical features\n8  numerical features\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.functions import isnan, when, count, col\ndata.select([count(when( col(c).isNull(), c)).alias(c) for c in data.columns]).show()\n#conclusion :From above it seems the data is clean with no missing values"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------+---------+----------+----------+-------+---+---+----+------+------+----------+----+-----+-------+------+\nCategory|Descript|DayOfWeek|PdDistrict|Resolution|Address|  X|  Y|hour|minute|second|dayOfMonth|year|month|weekday|season|\n+--------+--------+---------+----------+----------+-------+---+---+----+------+------+----------+----+-----+-------+------+\n       0|       0|        0|         0|         0|      0|  0|  0|   0|     0|     0|         0|   0|    0|      0|     0|\n+--------+--------+---------+----------+----------+-------+---+---+----+------+------+----------+----+-----+-------+------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["encoding_var = [i[0] for i in data.dtypes if (i[1]=='string') ]\nprint(encoding_var)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;Category&#39;, &#39;Descript&#39;, &#39;DayOfWeek&#39;, &#39;PdDistrict&#39;, &#39;Resolution&#39;, &#39;Address&#39;, &#39;weekday&#39;, &#39;season&#39;]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nstring_indexes = [StringIndexer(inputCol = c, outputCol = 'IDX_' + c, handleInvalid = 'keep') for c in encoding_var]\nstring_indexes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: [StringIndexer_0be3eb8fad94,\n StringIndexer_73cbc78a9cb8,\n StringIndexer_3703d93b4216,\n StringIndexer_53c7ef29d344,\n StringIndexer_b3221ddb0ec7,\n StringIndexer_5f6960947ae6,\n StringIndexer_61084669817b,\n StringIndexer_6d4e486faf45]</div>"]}}],"execution_count":8},{"cell_type":"code","source":["#ONE Hot Encoding \nfrom pyspark.ml.feature import OneHotEncoderEstimator\nonehot_indexes = [OneHotEncoderEstimator(inputCols = ['IDX_' + c], outputCols = ['OHE_' + c]) for c in encoding_var]\nonehot_indexes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: [OneHotEncoderEstimator_89340f040ada,\n OneHotEncoderEstimator_13f7deafcf8b,\n OneHotEncoderEstimator_06f04e7b73c5,\n OneHotEncoderEstimator_acee5e624dd0,\n OneHotEncoderEstimator_bd7c755bce21,\n OneHotEncoderEstimator_c734d045bab6,\n OneHotEncoderEstimator_927446583a70,\n OneHotEncoderEstimator_ac2c51b48af2]</div>"]}}],"execution_count":9},{"cell_type":"code","source":["#Visualizations:\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndata_pd=data.toPandas()\nplt.clf()\ndata_pd.plot(kind=\"scatter\", x=\"X\", y=\"Y\")\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#we can see an outlier in the dataset, removing it."],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["data=data.where('X<-122')\ndata_pd=data.toPandas()\nplt.clf()\ndata_pd.plot(kind=\"scatter\", x=\"X\", y=\"Y\")\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":12}],"metadata":{"name":"CrimesFeatureManipulations","notebookId":3924998272563575},"nbformat":4,"nbformat_minor":0}
