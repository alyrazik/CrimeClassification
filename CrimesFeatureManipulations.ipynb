{"cells":[{"cell_type":"code","source":["/FileStore/tables/train.csv"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#INPUT: train.csv\n#Output: \n\"\"\"\n\n1. Clean up wrong X and Y values (very few of them)\n\n2. visualize data.\n\n2. Parse input to get features: for e.g: get date, time, year, month, etc..)\n\n3. Select, and generate features.\n\n3. Remove outliers.\n\n4. do PCA\n\nOutput: train dataframe with features and labels column\n\n        test dataframe with features and lables column\n\n        visuals to provide insights on data that help select, and tune the models.       \n\n a toolbox list to choose from:\n\n         Typical graphical techniques used in EDA are\n\n\nBox plot\n\nHistogram\n\nMulti-vari chart\n\nRun chart\n\nPareto chart\n\nScatter plot\n\nStem-and-leaf plot\n\nParallel coordinates\n\nOdds ratio\n\nTargeted projection pursuit\n\nGlyph-based visualization methods such as PhenoPlot[8] and Chernoff faces\n\nProjection methods such as grand tour, guided tour and manual tour\n\nInteractive versions of these plots\n\n        Dimensionality reduction:\n\nMultidimensional scaling\n\nPrincipal component analysis (PCA)\n\nMultilinear PCA\n\nNonlinear dimensionality reduction (NLDR)\n\n        Typical quantitative techniques are:\nMedian polish\n\nTrimean\n\nOrdination\n\nHistory\n\n        \n\"\"\""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["filename=\"/FileStore/tables/train.csv\"\ndata=spark.read.csv(filename, header=True, inferSchema=True)\nprint(data.count())\nprint(len(data.columns))\ndata.printSchema() #the data was inferred properly. Class is an int. Features are double."],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">878049\n9\nroot\n-- Dates: timestamp (nullable = true)\n-- Category: string (nullable = true)\n-- Descript: string (nullable = true)\n-- DayOfWeek: string (nullable = true)\n-- PdDistrict: string (nullable = true)\n-- Resolution: string (nullable = true)\n-- Address: string (nullable = true)\n-- X: double (nullable = true)\n-- Y: double (nullable = true)\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["\"\"\"\nDates - timestamp of the crime incident\nCategory - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\nDescript - detailed description of the crime incident (only in train.csv)\nDayOfWeek - the day of the week\nPdDistrict - name of the Police Department District\nResolution - how the crime incident was resolved (only in train.csv)\nAddress - the approximate street address of the crime incident \nX - Longitude\nY - Latitude\n\"\"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: &#39;\\nDates - timestamp of the crime incident\\nCategory - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\\nDescript - detailed description of the crime incident (only in train.csv)\\nDayOfWeek - the day of the week\\nPdDistrict - name of the Police Department District\\nResolution - how the crime incident was resolved (only in train.csv)\\nAddress - the approximate street address of the crime incident \\nX - Longitude\\nY - Latitude\\n&#39;</div>"]}}],"execution_count":4},{"cell_type":"code","source":["#Parsing the time column to generate features, year, month, day, hour, season\nfrom pyspark.sql.functions import col, hour, minute, second, year, month, dayofmonth, date_format\n\ndef season(month):\n  switcher={\n    1:'winter',\n    2:'winter',\n    3:'spring',\n    4:'spring',\n    5:'spring',\n    6:'summer',\n    7:'summer',\n    8:'summer',\n    9:'autumn',\n    10:'autumn',\n    11:'autumn',\n    12:'winter'\n  }\n  return switcher.get(month,\"NA\")\n\nfrom pyspark.sql.types import StringType\nseason_udf_string= udf(lambda x: season(x), StringType())\n\ndata = data.withColumn(\"hour\", hour(col(\"Dates\"))).withColumn(\"minute\", minute(col(\"Dates\"))).withColumn(\"second\", second(col(\"Dates\"))).withColumn(\"dayOfMonth\", dayofmonth(col(\"Dates\"))).withColumn(\"year\", year(col(\"Dates\"))).withColumn(\"month\", month(col(\"Dates\"))).withColumn(\"dayOfWeek\", date_format(col(\"Dates\"), \"EEEE\")).withColumn(\"season\", season_udf_string(col(\"month\"))).drop(col(\"Dates\"))\n\ndata.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Category: string (nullable = true)\n-- Descript: string (nullable = true)\n-- dayOfWeek: string (nullable = true)\n-- PdDistrict: string (nullable = true)\n-- Resolution: string (nullable = true)\n-- Address: string (nullable = true)\n-- X: double (nullable = true)\n-- Y: double (nullable = true)\n-- hour: integer (nullable = true)\n-- minute: integer (nullable = true)\n-- second: integer (nullable = true)\n-- dayOfMonth: integer (nullable = true)\n-- year: integer (nullable = true)\n-- month: integer (nullable = true)\n-- season: string (nullable = true)\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["encoding_var = [i[0] for i in data.dtypes if (i[1]=='string') ]\nprint(encoding_var)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nstring_indexes = [StringIndexer(inputCol = c, outputCol = 'IDX_' + c, handleInvalid = 'keep') for c in encoding_var]\nstring_indexes"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#ONE Hot Encoding \nfrom pyspark.ml.feature import OneHotEncoderEstimator\nonehot_indexes = [OneHotEncoderEstimator(inputCols = ['IDX_' + c], outputCols = ['OHE_' + c]) for c in encoding_var]\nonehot_indexes"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"CrimesFeatureManipulations","notebookId":3924998272563575},"nbformat":4,"nbformat_minor":0}
